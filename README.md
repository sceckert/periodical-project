# A Medium-Scale Approach to the History of Literary Criticism: Machine-Reading the Review Column, 1866-1900

Book reviews in nineteenth-century periodicals seem like the perfect data for doing computer-assisted disciplinary history. The body of the review gives information about the words used by early generations of literary critics while the paratext provides semi-structured information about how these early literary critics read, evaluated, classified: they include section headings labeling the topic or genre of books under review alongside bibliographic information. Such material, when studied in aggregate, could provide valuable insight into the long history of literary criticism. Yet there's a significant obstacle to this work: important metadata created by nineteenth authors and editors is captured erratically (if at all) within full-text databases and the periodical indexes that reference them. 

My project aims to tackle this dilemma and develop a method for doing this kind of disciplinary history.  To do so, I've constructed a medium-sized collection of metadata that draws on both unsupervised and supervised models of reading. Working with a corpus of two key nineteenth century British periodicals over a 20 year period (1865-1885), this project collects metadata on the reviews works––capturing the review metadata as it exists in existing database and indexes, and using more granular data extraction to capture sections headings like  "new books," "general literature," or "critical notices"). I then pair this metadata with computer-assisted readings of the full texts, generating "topic models" of frequently co-occurring word clusters using [MALLET](http://mallet.cs.umass.edu/), a toolkit for probabilistic modeling. While the topic models offer the possibility of reading over a larger number of unlabeled texts, the metadata provides a way of slicing up these topic models based on the way these reviews were originally labeled and organized. The end goal here is to create a set of metadata that might be navigated in an interface or downloaded (as flat CSV files). 

Though the case study will be of practical use for Victorianists, the project aims to address  questions of interest to literary historians more generally. What patterns emerge when we look at an early literary review's subject headings over time? What can we learn from using machine-learning to sift through a loose, baggy category like "contemporary literature" as it was  used by reviewers during the four decades of specialization and discipline formation at the end of the century? Critical categories and vocabularies about them presents a particularly thorny problem for literary interpretation and classification of "topics" (see work by [Andrew Goldstone and Ted Underwood](https://muse.jhu.edu/article/558875/summary) or [John Laudun and Jonathan Goodman](https://muse.jhu.edu/article/524280/summary)). I hope to assuage some of these anxieties by leveraging the information already provided by nineteenth century review section headings, which themselves index, organize and classify their contents. 

For this project, I've collected all 271 different monthly (and occasionally bi-monthly) review columns in two prominent Victorian periodicals *The Fortnightly Review* and *The Contemporary Review*, with a total of around   449 different subsections and around 890 individual reviews. I've extracted and stored the bibliographic metadata in [a flat csv file](https://github.com/sceckert/periodical-project/blob/master/periodical-project-metadata.csv). I've then topic modeled the tokenized reviews. using the metadata to slice and analyze subsets of this very large topic model. Some of the preliminary results are exciting––for instance, the relatively late emergence of "fiction" as its own separate category within the broader category of "literature" reviews in *The Contemporary Review*. Check out my [project notebook](https://github.com/sceckert/periodical-project/blob/master/Periodical-Project.ipynb) for some of these visualizations and preliminary analysis. 
 
While relatively modest in scale (2 periodicals, a 20-year period), this narrower scope, I hope, will make this an achievable project and a test case for how topic modeling could be used more strategically in tandem with more curated metadata. For my own research, this work is essential. My goal with the project, however, is not just to provide a way to read and study the review section over time, but to provide a portable methodology useful for intellectual historians, genre, and narrative theorists and literary sociologists. By putting metadata at the forefront, I hope to also make a small bid for valuing data creation within digital humanities projects, as my project seeks to make data re-use as an important component as modeling. 
